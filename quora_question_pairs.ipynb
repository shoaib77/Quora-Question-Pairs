{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nfrom string import punctuation\n\n\nimport re\n\nimport matplotlib.pyplot as plt\n\n\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, Dense, Dropout, BatchNormalization, TimeDistributed, Input\nfrom keras.layers import Lambda, Activation, Flatten, Conv1D, concatenate\n\nfrom keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\nfrom keras import initializers\nfrom keras import backend as K",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "848ff70cd9bca8905180683a0f96d5dee34f30b8",
        "_cell_guid": "e36ed210-ecef-43ac-ac8f-8424d20bf0f5",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print(train.shape)\nprint(test.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f73ec16811d30951dfcbfc9204ac3b1b3c391701",
        "_cell_guid": "e90f1c0a-ff26-48d1-a801-60be6aeff283"
      },
      "cell_type": "markdown",
      "source": "Process The Data"
    },
    {
      "metadata": {
        "_uuid": "d754e25bcda828ac6eb749a1c10d7c13cc42bb49",
        "_cell_guid": "1425f8a6-f28d-4331-b841-7f42e410b797",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "train = train.fillna('empty')\ntest = test.fillna('empty')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8fa3eb68949201d220828113f981680e32f94d70",
        "_cell_guid": "6628aced-afb5-408e-9ac2-ef9094fbe9f9",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "stop_words = ['the','a','an','and','but','if','or','because','as','what','which','this','that','these','those','then',\n              'just','so','than','such','both','through','about','for','is','of','while','during','to','What','Which',\n              'Is','If','While','This']\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b5d5bd667451fc734573ad0d7b82cecfc6a5e0c8",
        "_cell_guid": "e99f05a0-33c7-424e-9edd-05f44356128d",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def text_to_wordlist(text, remove_stop_words=True, stem_words=False):\n    # Clean the text, with the option to remove stop_words and to stem words.\n    \n    # Convert words to lower case and split them\n    text = text.lower()\n\n    # Clean the text\n    text = re.sub(r\"[^A-Za-z0-9]\", \" \", text)\n    text = re.sub(r\"what's\", \"\", text)\n    text = re.sub(r\"What's\", \"\", text)\n    text = re.sub(r\"\\'s\", \" \", text)\n    text = re.sub(r\"\\'ve\", \" have \", text)\n    text = re.sub(r\"can't\", \"cannot \", text)\n    text = re.sub(r\"n't\", \" not \", text)\n    text = re.sub(r\"I'm\", \"I am\", text)\n    text = re.sub(r\" m \", \" am \", text)\n    text = re.sub(r\"\\'re\", \" are \", text)\n    text = re.sub(r\"\\'d\", \" would \", text)\n    text = re.sub(r\"\\'ll\", \" will \", text)\n    text = re.sub(r\"\\0k \", \"0000 \", text)\n    text = re.sub(r\" e g \", \" eg \", text)\n    text = re.sub(r\" b g \", \" bg \", text)\n    text = re.sub(r\"\\0s\", \"0\", text)\n    text = re.sub(r\" 9 11 \", \"911\", text)\n    text = re.sub(r\"e-mail\", \"email\", text)\n    text = re.sub(r\"\\s{2,}\", \" \", text)\n    text = re.sub(r\"quikly\", \"quickly\", text)\n    text = re.sub(r\" usa \", \" America \", text)\n    text = re.sub(r\" USA \", \" America \", text)\n    text = re.sub(r\" u s \", \" America \", text)\n    text = re.sub(r\" uk \", \" England \", text)\n    text = re.sub(r\" UK \", \" England \", text)\n    text = re.sub(r\"india\", \"India\", text)\n    text = re.sub(r\"china\", \"China\", text)\n    text = re.sub(r\"chinese\", \"Chinese\", text) \n    text = re.sub(r\"imrovement\", \"improvement\", text)\n    text = re.sub(r\"intially\", \"initially\", text)\n    text = re.sub(r\"quora\", \"Quora\", text)\n    text = re.sub(r\" dms \", \"direct messages \", text)  \n    text = re.sub(r\"demonitization\", \"demonetization\", text) \n    text = re.sub(r\"actived\", \"active\", text)\n    text = re.sub(r\"kms\", \" kilometers \", text)\n    text = re.sub(r\"KMs\", \" kilometers \", text)\n    text = re.sub(r\" cs \", \" computer science \", text) \n    text = re.sub(r\" upvotes \", \" up votes \", text)\n    text = re.sub(r\" iPhone \", \" phone \", text)\n    text = re.sub(r\"\\0rs \", \" rs \", text) \n    text = re.sub(r\"calender\", \"calendar\", text)\n    text = re.sub(r\"ios\", \"operating system\", text)\n    text = re.sub(r\"gps\", \"GPS\", text)\n    text = re.sub(r\"gst\", \"GST\", text)\n    text = re.sub(r\"programing\", \"programming\", text)\n    text = re.sub(r\"bestfriend\", \"best friend\", text)\n    text = re.sub(r\"dna\", \"DNA\", text)\n    text = re.sub(r\"III\", \"3\", text) \n    text = re.sub(r\"the US\", \"America\", text)\n    text = re.sub(r\"Astrology\", \"astrology\", text)\n    text = re.sub(r\"Method\", \"method\", text)\n    text = re.sub(r\"Find\", \"find\", text) \n    text = re.sub(r\"banglore\", \"Banglore\", text)\n    text = re.sub(r\" J K \", \" JK \", text)\n    \n    # Remove punctuation from text\n    text = ''.join([c for c in text if c not in punctuation])\n    \n    # Optionally, remove stop words\n    if remove_stop_words:\n        text = text.split()\n        text = [w for w in text if not w in stop_words]\n        text = \" \".join(text)\n    \n    # Optionally, shorten words to their stems\n    if stem_words:\n        text = text.split()\n        stemmer = SnowballStemmer('english')\n        stemmed_words = [stemmer.stem(word) for word in text]\n        text = \" \".join(stemmed_words)\n    \n    # Return a list of words\n    return(text)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b3a9a2faec0b5ee8d494d6b61f8d1efd114d9faf",
        "_cell_guid": "5939bc9d-9c81-4464-aa31-248b331e797b",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def process_questions(question_list, questions, question_list_name, dataframe):\n    '''transform questions and display progress'''\n    for question in questions:\n        question_list.append(text_to_wordlist(question))\n        if len(question_list) % 100000 == 0:\n            progress = len(question_list)/len(dataframe) * 100\n            print(\"{} is {}% complete.\".format(question_list_name, round(progress, 1)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "41f8505c3410031da43052e047c0c93930a022f3",
        "_cell_guid": "77149320-d9f0-46af-813a-d700a5b02b5a",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_question1 = []\nprocess_questions(train_question1, train.question1, 'train_question1', train)\n\n\n\ntrain_question2 = []\nprocess_questions(train_question2, train.question2, 'train_question2', train)\n\n\n\ntest_question1 = []\nprocess_questions(test_question1, test.question1, 'test_question1', test)\n\ntest_question2 = []\nprocess_questions(test_question2, test.question2, 'test_question2', test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f9678e76694eeeee62334a303033d92dfde2f0d2",
        "_cell_guid": "11a7a05a-fe20-439e-9463-d52582a535a6",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "lengths = []\nfor question in train_question1:\n    lengths.append(len(question.split()))\n\nfor question in train_question2:\n    lengths.append(len(question.split()))\n\n# Create a dataframe so that the values can be inspected\nlengths = pd.DataFrame(lengths, columns=['counts'])\n\n\n\nlengths.counts.describe()\n\n\nprint(np.percentile(lengths.counts, 99.0))\nprint(np.percentile(lengths.counts, 99.4))\nprint(np.percentile(lengths.counts, 99.5))\nprint(np.percentile(lengths.counts, 99.9))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ce19dd5261fa25a626485d32fba5d9cf337e9280",
        "_cell_guid": "ccb94169-090c-47d3-82f7-49563e28bcc7",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# tokenize the words for all of the questions\nall_questions = train_question1 + train_question2 + test_question1 + test_question2\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(all_questions)\nprint(\"Fitting is complete.\")\ntrain_question1_word_sequences = tokenizer.texts_to_sequences(train_question1)\nprint(\"train_question1 is complete.\")\ntrain_question2_word_sequences = tokenizer.texts_to_sequences(train_question2)\nprint(\"train_question2 is complete\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3f6fe436dabca2de6d5ea8bec1c88520d9cf99b7",
        "_cell_guid": "417fe27f-464d-4f75-bf3a-f5aab3f69329",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "test_question1_word_sequences = tokenizer.texts_to_sequences(test_question1)\nprint(\"test_question1 is complete.\")\ntest_question2_word_sequences = tokenizer.texts_to_sequences(test_question2)\nprint(\"test_question2 is complete.\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1e2f65ef6463e8fd19970c6906d433e224e733c2",
        "_cell_guid": "8a175b74-72fc-439a-be8a-c2ecd4da7974",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "word_index = tokenizer.word_index\nprint(\"Words in index: %d\" % len(word_index))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e73cc2ae5ea896c7aa2270c7fe3de5fbeb83ab97",
        "_cell_guid": "5e4fd6b3-de4e-49f3-9035-222bd683e9d6",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Pad the questions so that they all have the same length.\n\nmax_question_len = 36\n\ntrain_q1 = pad_sequences(train_question1_word_sequences, \n                              maxlen = max_question_len)\nprint(\"train_q1 is complete.\")\n\ntrain_q2 = pad_sequences(train_question2_word_sequences, \n                              maxlen = max_question_len)\nprint(\"train_q2 is complete.\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1d26305bfb356303cc3204273dea95b3405c0c23",
        "_cell_guid": "ac69fdb8-492a-44dd-9556-3891b626c2f9",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "test_q1 = pad_sequences(test_question1_word_sequences, \n                             maxlen = max_question_len,\n                             padding = 'post',\n                             truncating = 'post')\nprint(\"test_q1 is complete.\")\n\ntest_q2 = pad_sequences(test_question2_word_sequences, \n                             maxlen = max_question_len,\n                             padding = 'post',\n                             truncating = 'post')\nprint(\"test_q2 is complete.\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fbc32cb5e82950bea786e11f4819cbd42d0c9cf9",
        "_cell_guid": "215cfe96-f434-4979-9b4f-41196d841328",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "y_train = train.is_duplicate\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8f2a8f614b70af7be0d7772da2bcdb6bd16d87f0",
        "_cell_guid": "b9175974-8446-45df-94eb-1ef74e7d09c2",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "embedding_dim = 300\nnb_words = len(word_index)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5d007f875ae5e2a5089eb4696a8f47b5505dc047",
        "_cell_guid": "6c5aa6fc-8c0a-4b7f-941d-5f2c5f467304",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Setting the parameter\n\nunits = 128 # Number of nodes in the Dense layers\ndropout = 0.25 # Percentage of nodes to drop\nnb_filter = 32 # Number of filters to use in Convolution1D\nfilter_length = 3 # Length of filter for Convolution1D",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "806a948797ea8d8447642964112ed4a5c66d0cd9",
        "_cell_guid": "7c4e1496-42c3-46d5-be2c-c152fe61b3a7",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "inp1 = Input(shape=(max_question_len,), name='input_1')\nX = Embedding(input_dim= nb_words+1, \n              output_dim= embedding_dim, \n              input_length=max_question_len, \n              trainable= False\n             )(inp1)\nX = Conv1D(filters= nb_filter, kernel_size= filter_length, padding='same')(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\nX = Dropout(dropout)(X)\n\nX = Conv1D(filters= nb_filter, kernel_size= filter_length, padding='same')(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\nX = Dropout(dropout)(X)\nout1 = Flatten()(X)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3699a0301d498846d108494f77f23b31e2cfafc7",
        "_cell_guid": "991aac53-bb2a-4d66-b436-7e19a4a797ff",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "inp2 = Input(shape=(max_question_len,), name='input_2')\nX = Embedding(input_dim= nb_words+1, \n              output_dim= embedding_dim, \n              input_length=max_question_len, \n              trainable= False\n             )(inp2)\nX = Conv1D(filters= nb_filter, kernel_size= filter_length, padding='same')(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\nX = Dropout(dropout)(X)\n\nX = Conv1D(filters= nb_filter, kernel_size= filter_length, padding='same')(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\nX = Dropout(dropout)(X)\nout2 = Flatten()(X)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bacfa674e2fb66a4439163d3090faba1e11b9463",
        "_cell_guid": "bd979fff-7eb7-45f7-a257-49e7718491ab",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "inp3 = Input(shape=(max_question_len,), name='input_3')\nX = Embedding(input_dim= nb_words+1, \n              output_dim= embedding_dim, \n              input_length=max_question_len, \n              trainable= False\n             )(inp3)\nX = TimeDistributed(Dense(embedding_dim))(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\nX = Dropout(dropout)(X)\nout3 = Lambda(lambda x: K.max(x, axis=1), output_shape=(embedding_dim,))(X)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f2db4396955133eb86a9c703bc7c7f190e1f6a68",
        "_cell_guid": "71147af3-54b8-4cb2-9485-c46bc6a021cc",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "inp4 = Input(shape=(max_question_len,), name='input_4')\nX = Embedding(input_dim= nb_words+1, \n              output_dim= embedding_dim, \n              input_length=max_question_len, \n              trainable= False\n             )(inp4)\nX = TimeDistributed(Dense(embedding_dim))(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\nX = Dropout(dropout)(X)\nout4 = Lambda(lambda x: K.max(x, axis=1), output_shape=(embedding_dim,))(X)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3ab74529b98cd5bf8f0f6f56be485ededc871c4d",
        "_cell_guid": "864b7493-e13a-4d58-8979-12fe3c21cdea",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "merge12 = concatenate([out1, out2], name='merge_layer_1')\nX = Dense(units=units*2)(merge12)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\nX = Dropout(dropout)(X)\n\nX = Dense(units=units)(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\nmodel12 = Dropout(dropout)(X)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ac2c022385f88aaca784302594fd486b803e36e7",
        "_cell_guid": "41075d1d-ee79-4d73-8d5e-d09d317d04fd",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "merge34 = concatenate([out3, out4], name='merge_layer_2')\nX = Dense(units=units*2)(merge34)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\nX = Dropout(dropout)(X)\n\nX = Dense(units=units)(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\nmodel34 = Dropout(dropout)(X)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3df769cd4cc0097fa1908a2250f95305d0294c6f",
        "_cell_guid": "2ff00325-540b-476d-a175-95687bda5b22",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "merged = concatenate([model12, model34], name='final_merge')\nX = Dense(units=units*2)(merged)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\nX = Dropout(dropout)(X)\n\nX = Dense(units=units)(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\nX = Dropout(dropout)(X)\n\nX = Dense(units=units)(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\nX = Dropout(dropout)(X)\n\nX = Dense(units=1)(X)\nX = BatchNormalization()(X)\nout = Activation('sigmoid')(X)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "622bc89b0a83679dcf7c037476509095dae188c1",
        "_cell_guid": "c0f4248f-1e84-4966-8e22-a85e4c4015ca",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "model = Model(inputs=[inp1, inp2, inp3, inp4], outputs=out)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dbf5b271bafe4bd098bef4d0f504394938cdc392",
        "_cell_guid": "31e78b24-0f5a-4b89-b9da-ddf500940af2",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "76cc312d85082cfc42649c54c3b22500c9c0b969",
        "_cell_guid": "71f81374-c170-40bc-97df-061d85060e17",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from keras.utils import plot_model\nprint (model.summary())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "87662f0bbee01487cadd12d49f4c708595bec734",
        "_cell_guid": "2f1cffc1-bd11-49b1-83f5-ce1c3af39250",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "save_best_weights = 'question_pairs_weights.h5'\n\ncallbacks = [ModelCheckpoint(save_best_weights, monitor='val_loss', save_best_only=True),\n             EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')]\n\nhistory = model.fit([train_q1, train_q2, train_q1, train_q2],\n                    y_train,\n                    batch_size=256,\n                    epochs=3, \n                    validation_split=0.15,\n                    verbose=True,\n                    shuffle=True,\n                    callbacks=callbacks)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b6cace840783b7e84b0b8b0b8ecf28e7b4c922f5",
        "_cell_guid": "2425e2c1-3f5c-4aab-b5ce-9d619d382187",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Aggregate the summary statistics\nsummary_stats = pd.DataFrame({'epoch': [ i + 1 for i in history.epoch ],\n                              'train_acc': history.history['acc'],\n                              'valid_acc': history.history['val_acc'],\n                              'train_loss': history.history['loss'],\n                              'valid_loss': history.history['val_loss']})\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e8304d9fd95dfae47e8f042e50d417178144c786",
        "_cell_guid": "a6432586-5790-4238-9787-3efcef043283",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "summary_stats",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fb53ecc32d21959bf0d21064269f6d4616924b71",
        "_cell_guid": "0c0ea225-e83d-4b9e-9195-27ad81be8b8a",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.plot(summary_stats.train_loss) # Blue\nplt.plot(summary_stats.valid_loss) # Orange\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4b32fb6629b2d765d2d16aa6496b773045d56a11",
        "_cell_guid": "285b2c0e-2df8-44af-a096-f550fe84e10a",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Find the minimum validation loss during the training\nmin_loss, idx = min((loss, idx) for (idx, loss) in enumerate(history.history['val_loss']))\nprint('Minimum loss at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(min_loss))\nmin_loss = round(min_loss, 4)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "53b9ecf8d5c35cd0c0ca9dcb95a7e30b463b5792",
        "_cell_guid": "cb44496a-4c13-4473-a797-8a845062850b",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Make predictions with the best weights\n#model.load_weights(save_best_weights)\npredictions = model.predict([test_q1, test_q2, test_q1, test_q2], verbose = True, batch_size=512)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ef77e6543bba2946300f1245dcbcc1e2c8f6d760",
        "_cell_guid": "d7b49486-70c0-491d-8800-4d50e03a3d25",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Create submission\nsubmission = pd.DataFrame(predictions, columns=['is_duplicate'])\nsubmission.insert(0, 'test_id', test.test_id)\nfile_name = 'submission_{}.csv'.format(min_loss)\nsubmission.to_csv(file_name, index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "573c91ce5e208a62fddc15984a01d3aecb0a4fe3",
        "_cell_guid": "ce43cb90-b217-4fd8-b957-e15469f6fc5a",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "submission.head(50)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "438cd731093db977743e2ba812534a30457aac3b",
        "_cell_guid": "04ffe7fa-434e-463c-8c8d-3c20d7897a19",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "model.save('quora_model.h5py')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "26c18fc6cb26e173156f380ef03ebdb1ae8188dc",
        "_cell_guid": "1e86a5b6-f489-4ca8-950a-f1b4e42ca679",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "96fe1794d881096d642d1f6c9e7f5ad59e92516a",
        "_cell_guid": "005a03c2-e8c4-44a2-af88-8ca9549e0c3a",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d3012d29164977b658bbe03d41360b696d7b98ff",
        "_cell_guid": "0dd8155b-c325-4e67-8c63-7b294e4ee83d",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b4237e6347dcd787e9ec7997ba4267d98e325d92",
        "_cell_guid": "e8c9aa83-683b-4b9e-8e1a-67da3051cea3",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "version": "3.6.4",
      "file_extension": ".py",
      "mimetype": "text/x-python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}